# Adversarial-Attacks
Generating Adversarial Examples and testing them.

The neural networks are prone to various attackss by foreign elements willing to intrude the system.
They introduce some sort of noise in the dataset which fools the model into believing that the data belongs to one of the classes.
